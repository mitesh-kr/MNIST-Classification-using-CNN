# -*- coding: utf-8 -*-
"""M23MAC004.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gJTV_xUi-cAFbXJ5wU_HK0OkzOXIpiBY
"""

#Import required libraries
import torch
import numpy as np
from torch import nn
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

from util import  load_images, load_labels, train_validation_split , count_parameters

from model import CNN

from train import CNNTrainer
# Device assignment
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# Load data
X_train = load_images(file_path='/content/train-images.idx3-ubyte', data_count=60000)
y_train = load_labels(file_path='/content/train-labels.idx1-ubyte', data_count=60000)
X_test = load_images(file_path='/content/t10k-images.idx3-ubyte', data_count=10000)
y_test = load_labels(file_path='/content/t10k-labels.idx1-ubyte', data_count=10000)


# Split data into training, validation, and testing sets
X_train, X_validation, y_train, y_validation = train_validation_split(X_train, y_train, train_ratio=0.95)
X_test, y_test = X_test, y_test

# Move the data to available device
X_train, y_train = X_train.to(device), y_train.to(device)
X_validation, y_validation = X_validation.to(device), y_validation.to(device)
X_test, y_test = X_test.to(device), y_test.to(device)

# TASK 1
print('TASK 1')
# Initialize the model
cnn_model = CNN(input_shape=(1, 28, 28), output_shape = 10).to(device)


# Create training instance
trainer = CNNTrainer(model = cnn_model,
                     optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.0001),
                     loss_function = nn.CrossEntropyLoss(),
                     epochs = 10)

# Train the model
train_loss_list, validation_loss_list, train_accuracy_list, validation_accuracy_list = trainer.train(X_train, y_train, X_validation, y_validation)

# Plot loss
trainer.plot_loss_accuracy(epochs = 10, metric_values_list = [train_loss_list, validation_loss_list],
                     labels = ['Training Loss', 'Validation Loss'], ylabel = 'Loss',
                     title = 'Training and Validation Loss', colors=['red', 'black'])

# Plot accuracy
trainer.plot_loss_accuracy(epochs = 10, metric_values_list = [train_accuracy_list, validation_accuracy_list],
                     labels = ['Training Accuracy', 'Validation Accuracy'], ylabel = 'Accuracy',
                     title = 'Training and Validation Accuracy', colors=['green', 'brown'])

# Evaluate and plot confusion matrix
class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
trainer.evaluation_and_confusion_matrix(X_test, y_test, class_names)

#Number of trainable and non_trainable parameters
trainable_params = cnn_model.count_parameters()
print('Number of trainable parameters:',trainable_params)
print('Number of non_trainable parameters:', 28*28*10)

#Task 2
print('TASK 2')
# Apply the mapping to train and test labels
class_mapping = {
    0: 0, 6: 0,                       # Class 1: {0, 6}
    1: 1, 7: 1,                       # Class 2: {1, 7}
    2: 2, 3: 2, 8: 2, 5: 2,           # Class 3: {2, 3, 8, 5}
    4: 3, 9: 3                        # Class 4: {4, 9}
}
y_train = torch.tensor([class_mapping[x.item()] for x in y_train])
y_test= torch.tensor([class_mapping[x.item()] for x in y_test])

# Split data into training, validation, and testing sets
X_train, X_validation, y_train, y_validation = train_validation_split(X_train, y_train, train_ratio=0.95)
X_test, y_test = X_test, y_test

# Move the data to available device
X_train, y_train = X_train.to(device), y_train.to(device)
X_validation, y_validation = X_validation.to(device), y_validation.to(device)
X_test, y_test = X_test.to(device), y_test.to(device)

# Initialize the model
cnn_model = CNN(input_shape=(1, 28, 28), output_shape = 4).to(device)


# Create training instance
trainer = CNNTrainer(model = cnn_model,
                     optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.0001),
                     loss_function = nn.CrossEntropyLoss(),
                     epochs = 10)

# Train the model
train_loss_list, validation_loss_list, train_accuracy_list, validation_accuracy_list = trainer.train(X_train, y_train, X_validation, y_validation)

# Plot loss
trainer.plot_loss_accuracy(epochs=10, metric_values_list=[train_loss_list, validation_loss_list],
                     labels=['Training Loss', 'Validation Loss'], ylabel='Loss',
                     title='Training and Validation Loss', colors=['red', 'black'])

# Plot accuracy
trainer.plot_loss_accuracy(epochs=10, metric_values_list=[train_accuracy_list, validation_accuracy_list],
                     labels=['Training Accuracy', 'Validation Accuracy'], ylabel='Accuracy',
                     title='Training and Validation Accuracy', colors=['green', 'brown'])

# Evaluate and plot confusion matrix
class_names = ['0', '1', '2', '3']
trainer.evaluation_and_confusion_matrix(X_test, y_test, class_names)

#Number of trainable and non_trainable parameters
trainable_params = cnn_model.count_parameters()
print('Number of trainable parameters:',trainable_params)
print('Number of non_trainable parameters:', 28*28*10)